{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/daverod/Downloads/optimizely_cs\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daverod/opt/anaconda3/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:10: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  \"LightFM was compiled without OpenMP support. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools #to list the films\n",
    "import sys\n",
    "import pickle #to save/call the model\n",
    "from ast import literal_eval #to extract text from dictionaries\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "#hybrid model of choice\n",
    "import lightfm \n",
    "from lightfm import LightFM, cross_validation\n",
    "from lightfm.data import Dataset\n",
    "\n",
    "#subdirectory from Microsoft GitHub devoted to recommenders - has useful metrics used here\n",
    "from reco_utils.evaluation.python_evaluation import precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD & PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(infile1, infile2):\n",
    "    a = pd.read_csv(infile1)\n",
    "    a.rename(columns={'userId': 'userID','movieId':'itemID'}, inplace=True)\n",
    "\n",
    "    #chose genre as the text feature (item attribute)\n",
    "    df = pd.read_csv(infile2)[['id','genres']]\n",
    "    df2 = df.drop(df[df['genres'] == '[]'].index, axis=0).reset_index(drop=True)\n",
    "    df2['genres'] = df2['genres'].apply(lambda x: [x['name'] for x in literal_eval(x)])\n",
    "    df2.rename(columns={'id': 'itemID'}, inplace=True)\n",
    "\n",
    "    movie_genre = df2['genres']\n",
    "    all_movie_genre = sorted(list(set(itertools.chain.from_iterable(movie_genre))))\n",
    "\n",
    "    #make a single base dataset\n",
    "    new_data = a.join(df2, on='itemID', how='left', lsuffix='a')\n",
    "    new_data.drop(['timestamp','itemID'],axis=1,inplace=True)\n",
    "    new_data.rename(columns={'itemIDa': 'itemID'}, inplace=True)\n",
    "\n",
    "    dataset = Dataset()\n",
    "    dataset.fit(a['userID'], a['itemID'], item_features=all_movie_genre)\n",
    "    item_features = dataset.build_item_features((x, y) for x,y in zip(a.itemID, movie_genre))\n",
    "\n",
    "    (interactions, weights) = dataset.build_interactions(a.iloc[:, 0:3].values)\n",
    "\n",
    "    return a, movie_genre, item_features, interactions, weights, all_movie_genre\n",
    "\n",
    "a, movie_genre, item_features, interactions, weights, all_movie_genre = load_data(infile1='/Users/daverod/Downloads/optimizely_cs/data/ratings_small.csv'\n",
    ",infile2='/Users/daverod/Downloads/optimizely_cs/data/movies_metadata_extract.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ints):\n",
    "    #scatter into train + test\n",
    "    train_interactions, test_interactions = cross_validation.random_train_test_split(ints, test_percentage=0.25,\n",
    "random_state=np.random.RandomState(42))\n",
    "    \n",
    "    return train_interactions, test_interactions\n",
    "\n",
    "train_interactions, test_interactions = split_data(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data(trnint, atts):\n",
    "    model = LightFM(loss='warp', no_components=25, learning_rate=0.25, \n",
    "                     item_alpha=1e-6, user_alpha=1e-6, random_state=np.random.RandomState(42))\n",
    "\n",
    "    model.fit(interactions=trnint, item_features=atts, epochs=20)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = model_data(train_interactions, item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_prep(ints,inp,lst1,lst2):\n",
    "    uids, iids, interaction_data = cross_validation._shuffle(ints.row, ints.col\n",
    "                            , ints.data, random_state=np.random.RandomState(42))\n",
    "    \n",
    "    cutoff = int((1.0 - 0.25) * len(uids))\n",
    "    \n",
    "    test_idx = slice(cutoff, None)\n",
    "    \n",
    "    dataset = Dataset()\n",
    "    dataset.fit(a['userID'], a['itemID'], item_features=all_movie_genre)\n",
    "    item_features = dataset.build_item_features((x, y) for x,y in zip(a.itemID, movie_genre))\n",
    "    (interactions, weights) = dataset.build_interactions(a.iloc[:, 0:3].values)\n",
    "    \n",
    "    uid_map, ufeature_map, iid_map, ifeature_map = dataset.mapping()\n",
    "    \n",
    "    return test_idx, uids, iids, uid_map, iid_map\n",
    "\n",
    "test_idx, uids, iids, uid_map, iid_map = pre_prep(interactions, a, all_movie_genre, movie_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get actual ratings for test set\n",
    "def prepare_test_df(test_idx, uids, iids, uid_map, iid_map, weights):\n",
    "    test_df = pd.DataFrame(\n",
    "        zip(\n",
    "            uids[test_idx],\n",
    "            iids[test_idx],\n",
    "            [list(uid_map.keys())[x] for x in uids[test_idx]],\n",
    "            [list(iid_map.keys())[x] for x in iids[test_idx]],\n",
    "        ),\n",
    "        columns=[\"uid\", \"iid\", \"userID\", \"itemID\"],\n",
    "    )\n",
    "\n",
    "    dok_weights = weights.todok()\n",
    "    test_df[\"rating\"] = test_df.apply(lambda x: dok_weights[x.uid, x.iid], axis=1)\n",
    "\n",
    "    return test_df[[\"userID\", \"itemID\", \"rating\"]]\n",
    "\n",
    "test_df = prepare_test_df(test_idx, uids, iids, uid_map, iid_map, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data, uid_map, iid_map, interactions, model, num_threads\n",
    "                   , user_features, item_features):\n",
    "    \n",
    "    #get predicted ratings for test set - note the longest part of code (approx 20-40 mins)\n",
    "    \n",
    "    #num_threads: note my PC only has 2 cores - suggest to set this to cores of your PC\n",
    "    \n",
    "    users, items = [], []\n",
    "    \n",
    "    item = list(data.itemID.unique())\n",
    "    \n",
    "    for user in data.userID.unique():\n",
    "        user = [user] * len(item)\n",
    "        users.extend(user)\n",
    "        items.extend(item)\n",
    "        \n",
    "    all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\": items})\n",
    "    all_predictions[\"uid\"] = all_predictions.userID.map(uid_map)\n",
    "    all_predictions[\"iid\"] = all_predictions.itemID.map(iid_map)\n",
    "    dok_weights = interactions.todok()\n",
    "    all_predictions[\"rating\"] = all_predictions.apply(lambda x: dok_weights[x.uid, x.iid], axis=1)\n",
    "    all_predictions = all_predictions[all_predictions.rating < 1].reset_index(drop=True)\n",
    "    all_predictions = all_predictions.drop(\"rating\", axis=1)\n",
    "    \n",
    "    all_predictions['prediction'] = all_predictions.apply(lambda x: model.predict(user_ids=int(x[\"uid\"]),\n",
    "                                              item_ids=[x[\"iid\"]],\n",
    "            user_features=user_features,item_features=item_features,num_threads=num_threads,)[0], axis=1,)\n",
    "    \n",
    "    return all_predictions[['userID','itemID','prediction']]\n",
    "\n",
    "all_predictions = get_predictions(data=a, uid_map=uid_map, iid_map=iid_map, interactions=train_interactions\n",
    "                , model=model, num_threads=2, user_features=None, item_features=item_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@K:\t0.123\n",
      "Recall@K:\t0.047\n"
     ]
    }
   ],
   "source": [
    "#focus on precision (% actually correct) + recall (coverage of all films in predictions)\n",
    "def eval_metrics(rating_true, rating_pred, k):\n",
    "    precision = precision_at_k(rating_true=rating_true, rating_pred=rating_pred, k=k)\n",
    "\n",
    "    recall = recall_at_k(rating_true=rating_true, rating_pred=rating_pred, k=k)\n",
    "\n",
    "    print(f\"Precision@K:\\t{precision:.3f}\", f\"Recall@K:\\t{recall:.3f}\", sep='\\n')\n",
    "    \n",
    "eval_metrics(rating_true=test_df, rating_pred=all_predictions, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **RANK 20, TOP 10:**\n",
    "*PRECISION: 0.093, RECALL: 0.035*\n",
    "- **RANK 25, TOP 10:**\n",
    "*PRECISION: 0.123, RECALL: 0.047*\n",
    "- **RANK 30, TOP 10:**\n",
    "*PRECISION: 0.096, RECALL: 0.037*\n",
    "- **RANK 40, TOP 10:**\n",
    "*PRECISION: 0.050, RECALL: 0.026*\n",
    "---\n",
    "- **RANK 20, TOP 20:**\n",
    "*PRECISION: 0.103, RECALL: 0.078*\n",
    "- **RANK 30, TOP 20:**\n",
    "*PRECISION: 0.106, RECALL: 0.076*\n",
    "- **RANK 40, TOP 20:**\n",
    "*PRECISION: 0.059, RECALL: 0.052*\n",
    "---\n",
    "**<font color=Red>Best model for top 10 has rank of 25</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(dset, to):\n",
    "    return dset.to_csv(to ,index=False)\n",
    "\n",
    "save_file(dset=all_predictions, to='/Users/daverod/Downloads/optimizely_cs/data/the_prediction_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(mdl, to):\n",
    "    return pickle.dump(mdl, open(to, 'wb'))\n",
    "\n",
    "save_model(mdl=model, to='/Users/daverod/Downloads/optimizely_cs/model/the_model_file.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
